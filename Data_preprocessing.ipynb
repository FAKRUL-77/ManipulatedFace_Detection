{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manipulate_path = 'manipulated_sequences/DeepFakeDetection/'\n",
    "# original_path = 'original_sequences/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mvd = os.walk(manipulate_path)\n",
    "# manipulated_data = []\n",
    "# original_data = []\n",
    "# import os\n",
    "# for root, dirs, files in os.walk(manipulate_path, topdown=False):\n",
    "#    for name in files:\n",
    "#       directory = os.path.join(root, name)\n",
    "#       manipulated_data.append(directory)\n",
    "\n",
    "# for root, dirs, files in os.walk(original_path, topdown=False):\n",
    "#    for name in files:\n",
    "#       directory = os.path.join(root, name)\n",
    "#       original_data.append(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__call__(): incompatible function arguments. The following argument types are supported:\n    1. (self: _dlib_pybind11.fhog_object_detector, image: array, upsample_num_times: int=0) -> _dlib_pybind11.rectangles\n\nInvoked with: <_dlib_pybind11.fhog_object_detector object at 0x000002588C3E69B0>, None, 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-6b9d50b3b71e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[0msec\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mframeRate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[0msec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m         \u001b[0msuccess\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m     \u001b[0mcap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdestroyAllWindows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-6b9d50b3b71e>\u001b[0m in \u001b[0;36mgetFrame\u001b[1;34m(sec)\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mcap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCAP_PROP_POS_MSEC\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msec\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mhasFrames\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[0mdetected\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdetector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m         \u001b[0mimg_h\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_w\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasFrames\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: __call__(): incompatible function arguments. The following argument types are supported:\n    1. (self: _dlib_pybind11.fhog_object_detector, image: array, upsample_num_times: int=0) -> _dlib_pybind11.rectangles\n\nInvoked with: <_dlib_pybind11.fhog_object_detector object at 0x000002588C3E69B0>, None, 1"
     ]
    }
   ],
   "source": [
    "# import cv2\n",
    "# import dlib\n",
    "# import numpy as np\n",
    "\n",
    "# detector = dlib.get_frontal_face_detector()\n",
    "\n",
    "# i = 1\n",
    "\n",
    "# img_size = 64\n",
    "# margin = 0.2\n",
    "# frame_count = 0\n",
    "\n",
    "# for video in manipulated_data:\n",
    "#     cap = cv2.VideoCapture(video)\n",
    "#     def getFrame(sec):\n",
    "#         cap.set(cv2.CAP_PROP_POS_MSEC, sec*1000)\n",
    "#         hasFrames, image = cap.read()\n",
    "#         detected = detector(image, 1)\n",
    "#         img_h, img_w, _ = np.shape(image)\n",
    "#         if hasFrames:\n",
    "#             if len(detected) > 0:\n",
    "#                 for j, d in enumerate(detected):\n",
    "#                     x1, y1, x2, y2, w, h = d.left(), d.top(), d.right() + 1, d.bottom() + 1, d.width(), d.height()\n",
    "#                     xw1 = max(int(x1 - margin * w), 0)\n",
    "#                     yw1 = max(int(y1 - margin * h), 0)\n",
    "#                     xw2 = min(int(x2 + margin * w), img_w - 1)\n",
    "#                     yw2 = min(int(y2 + margin * h), img_h - 1)\n",
    "#                     face =  image[yw1:yw2 + 1, xw1:xw2 + 1, :]\n",
    "#                     cv2.imwrite('manipulated/DeepFakeDetection_' + str(i) + '_video_' + str(count) + '.jpg', face)\n",
    "#         return hasFrames\n",
    "#     sec = 0.3\n",
    "#     count = 1\n",
    "# #     success = getFrame(sec)\n",
    "    \n",
    "#     while success:\n",
    "#         count += 1\n",
    "#         sec += frameRate\n",
    "#         sec = round(sec, 2)\n",
    "#         success = getFrame(sec)\n",
    "#     cap.release()\n",
    "#     cv2.destroyAllWindows()  \n",
    "#     i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-825a55ce13c1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[0msec\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mframeRate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[0msec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m         \u001b[0msuccess\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m     \u001b[0mi\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-21-825a55ce13c1>\u001b[0m in \u001b[0;36mgetFrame\u001b[1;34m(sec)\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdetector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetect_faces\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m         \u001b[0mbox\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'box'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;31m#         print(keypoints)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# import cv2\n",
    "# from mtcnn import MTCNN\n",
    "# import numpy as np\n",
    "\n",
    "# i = 1\n",
    "\n",
    "# for video in original_data:\n",
    "#     detector = MTCNN()\n",
    "#     cap = cv2.VideoCapture(video)\n",
    "#     def getFrame(sec):\n",
    "#         cap.set(cv2.CAP_PROP_POS_MSEC, sec*1000)\n",
    "#         hasFrames, image = cap.read()\n",
    "#         result = detector.detect_faces(image)\n",
    "        \n",
    "#         box = result[0]['box']\n",
    "# #         print(keypoints)\n",
    "        \n",
    "#         if hasFrames:\n",
    "#             face = image[box[1]:box[1]+box[3], box[0]:box[0]+box[2]]\n",
    "# #             print(face, box[0], box[1], box[2], box[3])\n",
    "            \n",
    "#             cv2.imwrite('original/original_' + str(i) + '_video_' + str(count) + '.jpg', face)\n",
    "# #             cv2.imwrite('original/original_' + str(i) + '_video_' + str(count) + '.jpg', keypoints)\n",
    "#         return hasFrames\n",
    "#     sec = 0.3\n",
    "#     count = 1\n",
    "#     frameRate = 1\n",
    "#     success = getFrame(sec)\n",
    "    \n",
    "#     while success:\n",
    "#         count += 1\n",
    "#         sec += frameRate\n",
    "#         sec = round(sec, 2)\n",
    "#         success = getFrame(sec)\n",
    "#     i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import dlib\n",
    "# import numpy as np\n",
    "\n",
    "\n",
    "# i = 1\n",
    "\n",
    "# img_size = 64\n",
    "# margin = 0.2\n",
    "# frame_count = 0\n",
    "# for k in range(1, 11):\n",
    "#     detector = dlib.get_frontal_face_detector()\n",
    "#     cap = cv2.VideoCapture(original_data[k])\n",
    "#     def getFrame(sec):\n",
    "#         cap.set(cv2.CAP_PROP_POS_MSEC, sec*1000)\n",
    "#         hasFrames, image = cap.read()\n",
    "#         detected = detector(image, 1)\n",
    "#         img_h, img_w, _ = np.shape(image)\n",
    "#         if hasFrames:\n",
    "#             if len(detected) > 0:\n",
    "#                 for j, d in enumerate(detected):\n",
    "#                     x1, y1, x2, y2, w, h = d.left(), d.top(), d.right() + 1, d.bottom() + 1, d.width(), d.height()\n",
    "#                     xw1 = max(int(x1 - margin * w), 0)\n",
    "#                     yw1 = max(int(y1 - margin * h), 0)\n",
    "#                     xw2 = min(int(x2 + margin * w), img_w - 1)\n",
    "#                     yw2 = min(int(y2 + margin * h), img_h - 1)\n",
    "#                     face =  image[yw1:yw2 + 1, xw1:xw2 + 1, :]\n",
    "\n",
    "#                     cv2.imwrite('original/original_' + str(i) + '_video_' + str(count) + '.jpg', face)\n",
    "#         return hasFrames\n",
    "#     sec = 1\n",
    "#     count = 1\n",
    "#     success = getFrame(sec)\n",
    "\n",
    "#     while success:\n",
    "#         count += 1\n",
    "#         sec += frameRate\n",
    "#         sec = round(sec, 2)\n",
    "#         success = getFrame(sec) \n",
    "#     cap.release()\n",
    "#     cv2.destroyAllWindows()\n",
    "#     i += 1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
